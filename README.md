The end goal of this project is for the user to be able to place various sound sources inside a building or room at different locations, for my program to track the users head orientation and location via various sensors, and to then update the sound output that is sent to the users headphones/earbuds to create a more immersive audio experience.

Hopefully one could create interesting audioscapes to experiment with:

-A jungle would maybe consist of a waterfall off on one side of a room, different birds and animals placed at various locations, and maybe a raining sound throughout the scene. (not sure if it can be done quickly enough in real time, but potentially detecting steps by the user and creating crunching leaves or sand sounds??)
-A beach with waves on one side, possibly crashing up against rocks, seagulls fluttering about overhead, a light wind throughout the scene, and distant ship horns.
First goal is to get audio output to change with head orientation first, and then hopefully get location working as well to again create more interesting experiences and more potential use cases in the world.

Not sure if no visual element will make this not a very interesting or fun experience to have.
